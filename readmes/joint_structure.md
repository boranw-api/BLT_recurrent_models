# Joint Structure & Trajectory Visualization

This document explains the **Joint Structure** visualization generated by the `rnn_test.py` script. This figure creates a unified geometric map of the model's internal representations, allowing you to simultaneously visualize the model's hierarchy (layers), dynamics (recurrent time steps), and domain specificity (Faces vs. Objects).

## 1. How to Generate

To create this figure, use the `rnn_test.py` script with the `joint_structure` MDS type. The key flag for separating domains is `--split-by-label`.

```bash
python rnn_test.py \
    --mds-type joint_structure \
    --split-by-label \
    --model-path ./blt_local_cache/path_to_your_model/blt_full_objects.pt
```

**Key Arguments:**
*   `--mds-type joint_structure`: Calculates a massive joint representational space including all target layers and time steps.
*   `--split-by-label`: Splits the input data into groups based on their label (e.g., Faces vs. Objects) before calculating trajectories.
*   (Optional) `--layer-categories`: JSON string specifying which layers to include (defaults to `output_0` through `output_5`).

## 2. Methodology

The visualization is built using **Representational Similarity Analysis (RSA)** and **Multidimensional Scaling (MDS)**:

1.  **Activations**: We run the model on a test set containing both Faces and Objects.
2.  **Splitting**: If `--split-by-label` is enabled, activations are separated into two groups (Faces and Objects). To ensure a fair geometric comparison, we enforce equal sample sizes between groups.
3.  **RDM Calculation**: For every layer ($L$), every time step ($t$), and every group ($G$), we compute a **Representational Dissimilarity Matrix (RDM)**. This matrix describes the distances between all pairs of images in that specific state.
4.  **Joint Embedding**: We construct a meta-matrix comparing *all* RDMs against *all* other RDMs (using Cosine similarity).
5.  **MDS Projection**: We project this high-dimensional meta-matrix into 2D space. Points that are close together in this plot represent model states that "see" the world in a geometrically similar way.

## 3. How to Interpret

The figure encodes three dimensions of information into a single 2D plot:

### A. Layers (Colors)
*   Each **Color** represents a distinct layer of the network (e.g., **Blue** = Layer 0, **Orange** = Layer 1, etc.).
*   The progression of colors typically moves across the plot, showing the feedforward hierarchical transformation of data.
*   **Gray Dashed Lines** (inter-layer): Connect the *last* time step of Layer $N$ to the *first* time step of Layer $N+1$, visualizing the feedforward link.

### B. Input Domain (Line Style)
When split by label, every layer has two distinct trajectories:
*   **Solid Lines (â€”)**: Trajectory for **Faces**.
*   **Dashed Lines (- -)**: Trajectory for **Objects**.
*   **Interpretation**:
    *   **Parallel Tracking**: If the solid and dashed lines follow nearly identical paths, the layer processes Faces and Objects using a shared geometry.
    *   **Divergence**: If the lines separate significantly, the layer has developed specialized representational geometries for the different domains.

### C. Time (Gradient & dots)
*   **Dots**: Represent discrete recurrent time steps ($t_0, t_1, t_2...$).
*   **Gradient**: Lines fade from transparent (early time) to opaque (late time), indicating the direction of flow.
*   **Path Length**:
    *   **Long Curves**: Indicate significant computation and state evolution during the recurrent passes.
    *   **Tight Knots**: Indicate a stable fixed point where the representation stops changing.

### D. MDS Invariance and Plotting under the Same Dimension
If you calculate an MDS space for "Faces" (Space A) and a separate MDS space for "Objects" (Space B), you cannot directly compare the coordinates or overlay them because MDS is invariant to rotation and reflection. The "East" direction in Space A might mean something completely different than "East" in Space B.

To compare them validly, you would need to use:

Procrustes Alignment: This is a statistical technique that takes two shapes (point clouds) and finds the optimal translation, rotation, and scaling to superimpose them. This would allow you to see if the shape of the trajectory is the same, even if the MDS projection rotated it differently.
Second-Order Isomorphism (RSA of RSA): Instead of comparing the MDS plots, you compare the RDMs (Representational Dissimilarity Matrices) directly. You can calculate the correlation between the Face-RDM and the Object-RDM. A high correlation means the network preserves the same relative geometry for both domains, regardless of the absolute coordinate space.
Why the current "Joint" approach is often better: The current plot you have computes a single joint embedding. This forces both Faces and Objects into the same coordinate system from the start. This allows you to directly interpret the distance between a Face trajectory and an Object trajectory as a real representational difference without needing alignment post-processing.

## Summary Checklist
| Visual Element | Meaning |
| :--- | :--- |
| **Color** | Network Layer (Hierarchy) |
| **Solid Line** | Face Inputs |
| **Dashed Line** | Object Inputs |
| **Dot Sequence** | Recurrent Time Steps (Dynamics) |
| **Spatial Distance** | Representational Dissimilarity |




Figure Explanation & Usage Guide
1. What is this figure?
This is a Joint Representation RDM Structure Matrix (often called a "Second-Order RDM" or "RDM of RDMs"). It visualizes the meta-similarity of the model's internal representations across all layers and time steps simultaneously.

Instead of showing what the model sees (e.g., "this image looks like a dog"), this figure shows how the geometry of the Representation space changes as information flows through the network layers and evolves over recurrent time steps.

2. How it is created (Methodology)
Feature Extraction:

We run the model on a fixed set of test images (e.g., 1000 images).
For every single combination of Layer (e.g., Output 0, Output 1...) and Time Step (t=0, t=1, t=2...), we record the activation vectors for all images.
First-Order RDM Calculation:

For each specific 

(Layer, Time)
 state, we compute a Representational Dissimilarity Matrix (RDM).
An RDM is a square matrix (Image x Image) where each value represents the distance between two images in that specific high-dimensional feature space. This captures the "geometric fingerprint" of that layer-time state.
Second-Order RDM Calculation (RDM Comparison):

We then treat each flattened RDM from Step 2 as a single data point.
We calculate the similarity (using Cosine Similarity by default) between every pair of RDMs.
The resulting large matrix (Total Steps x Total Steps) tells us: "How similar is the representational geometry at (Layer A, Time T1) to the geometry at (Layer B, Time T2)?"
3. How to Interpret the Visualization
Axes: Both X and Y axes represent the sequence of all layers laid out in order of time. The labels indicate the Layer blocks.

White Grid Lines: These lines mark the boundaries between different Layers (e.g., separating Output 0 from Output 1).
Inside a Block: Within each grid block, the axis progresses through time steps ($t_0 \to t_n$).
Color Scale:

Blue (Cool colors): Indicates High Similarity (Low Distance). The geometries are nearly identical.
Red (Warm colors): Indicates High Dissimilarity (High Distance). The geometries are very different.
Key Patterns to Look For:

The Diagonal: It is always dark blue because every state is identical to itself.
Block Diagonal Structure:
If you see large blue squares along the diagonal corresponding to a specific layer, it means the representation is stable across time within that layer (recurrence isn't changing the geometry much).
If you see a gradient (blue fading to red) within a diagonal block, it means the representation is evolving dynamically over time.
Off-Diagonal Patterns:
This shows similarity between layers.
If Layer N and Layer N+1 have a blue intersection, it means the transformation between layers is smooth and preserving geometry.
If the intersection is red, the network is performing a radical transformation between those layers.
Use this explanation when presenting the figure to collaborators to clarify that we are analyzing the stability and evolution of the representational manifolds themselves, not just individual neuron activations.